# Performance Optimization Guide

## üöÄ Otimiza√ß√µes Implementadas

### 1. ‚úÖ RAG Cache
**Localiza√ß√£o:** `src/rag/retriever.py`

- Cache em mem√≥ria para resultados de busca RAG
- Chave: `(query[:160], discipline, k)`
- FIFO eviction quando atinge 128 entradas
- **Impacto:** Reduz 30 chamadas RAG ‚Üí 3 chamadas (uma por quest√£o)

**Logs:**
```
RAG: cache hit
```

---

### 2. ‚úÖ Paraleliza√ß√£o Otimizada
**Localiza√ß√£o:** `src/utils/helpers.py`

- Semaphore aumentado de **2 ‚Üí 10** (default)
- Configur√°vel via `API_CONCURRENCY` env var
- Throttle configur√°vel via `API_THROTTLE_SLEEP` (default 0.2s)

**Como ajustar:**
```bash
export API_CONCURRENCY=15  # Aumenta paralelismo
export API_THROTTLE_SLEEP=0.1  # Reduz delay entre chamadas
```

**Aten√ß√£o:**
- Se receber **429 (Rate Limit)**: reduza `API_CONCURRENCY` ou aumente `API_THROTTLE_SLEEP`
- Gemini free-tier: recomendado `API_CONCURRENCY=5` e `API_THROTTLE_SLEEP=0.5`

---

### 3. ‚úÖ Performance Logging
**Localiza√ß√£o:** 
- `src/utils/helpers.py` (`measure_time` context manager)
- `src/agents/dspy_examiner.py`
- `src/agents/dspy_arbiter.py`
- `src/rag/retriever.py`

**Logs de Tempo:**
```
‚è≥ Iniciando: DSPy Examiner CORRETOR_1 - Question Q1...
‚úÖ Conclu√≠do: DSPy Examiner CORRETOR_1 - Question Q1 em 3.2456 segundos.

‚è≥ Iniciando: RAG Retrieval (Similarity Search)...
‚úÖ Conclu√≠do: RAG Retrieval (Similarity Search) em 0.1234 segundos.
```

**Como usar:**
```python
from src.utils.helpers import measure_time

with measure_time("Nome da Opera√ß√£o"):
    # c√≥digo aqui
    pass
```

---

### 4. ‚úÖ Streamlit Progress Streaming
**Localiza√ß√£o:** `app/main.py`

- Progress bars durante gera√ß√£o de quest√µes
- Progress bars durante simula√ß√£o de respostas
- Progress bars durante corre√ß√£o
- Status containers com feedback visual em tempo real

**Features:**
- `st.status()` com expans√£o autom√°tica
- `st.progress()` com percentual
- Mensagens de feedback por fase (RAG, Corretor 1, Corretor 2, √Årbitro)

---

### 5. ‚úÖ Batch Processing Otimizado
**Localiza√ß√£o:** `app/main.py` (Batch Processing mode)

**Estrat√©gias:**
- **Chunking:** Processa alunos em lotes (default: 4)
- **Cooldown:** Pausa entre lotes para evitar rate limits
- **Paralelismo por quest√£o:** Todos os alunos respondem Q1 em paralelo, depois Q2, etc.

**Configura√ß√£o:**
```bash
export BATCH_CHUNK_SIZE=4  # Alunos por lote
export BATCH_COOLDOWN_SLEEP=0.0  # Pausa entre lotes (segundos)
```

**Exemplo de fluxo:**
1. **Gerar 5 quest√µes** ‚Üí 5 chamadas LLM sequenciais
2. **Simular 30 alunos √ó 5 quest√µes:**
   - Loop: Q1 ‚Üí 30 alunos em paralelo (usando `safe_gather`)
   - Loop: Q2 ‚Üí 30 alunos em paralelo
   - ...
   - Total: 150 chamadas em 5 lotes
3. **Corrigir 30 alunos √ó 5 quest√µes:**
   - Q1: 30 corre√ß√µes em chunks de 4 ‚Üí ~8 lotes
   - Cada corre√ß√£o = 2 corretores + √°rbitro (se divergir)
   - Total: ~300-450 chamadas (dependendo de diverg√™ncias)

---

## üìä Benchmarks Esperados

### Antes da Otimiza√ß√£o
- 10 alunos √ó 3 quest√µes = **~10 minutos**
- Rate limits frequentes (429)
- UI congelada sem feedback

### Depois da Otimiza√ß√£o
- 10 alunos √ó 3 quest√µes = **~2-3 minutos**
- Cache RAG reduz 90% das buscas
- Paralelismo 5x maior (2 ‚Üí 10)
- Feedback visual em tempo real

### Gemini Free-Tier (Recomendado)
```bash
export API_CONCURRENCY=5
export API_THROTTLE_SLEEP=0.5
export BATCH_CHUNK_SIZE=3
export BATCH_COOLDOWN_SLEEP=1.0
```

Tempo esperado: **~4-5 minutos** para 10 alunos √ó 3 quest√µes

---

## üîç Como Monitorar Performance

### 1. Logs de Tempo
```bash
streamlit run app/main.py 2>&1 | grep "Conclu√≠do:"
```

### 2. Cache Hits
```bash
streamlit run app/main.py 2>&1 | grep "cache hit"
```

### 3. Rate Limits
```bash
streamlit run app/main.py 2>&1 | grep -E "(429|rate limit)"
```

---

## üõ†Ô∏è Troubleshooting

### Erro: 429 Too Many Requests
**Solu√ß√£o:**
```bash
export API_CONCURRENCY=3
export API_THROTTLE_SLEEP=1.0
export BATCH_COOLDOWN_SLEEP=2.0
```

### Lentid√£o: Cache n√£o est√° funcionando
**Debug:**
```python
# Adicione em retriever.py
logger.info(f"Cache size: {len(_RAG_CACHE)}")
logger.info(f"Cache keys: {list(_RAG_CACHE.keys())}")
```

### UI congelando no Streamlit
**Causa:** Loop de evento bloqueado  
**Solu√ß√£o:** Todas as opera√ß√µes async j√° usam `run_async()` que cria novo event loop

---

## üìà Pr√≥ximas Otimiza√ß√µes (Opcional)

### 1. Persistent Cache (Redis/SQLite)
- Cache sobrevive a restarts do Streamlit
- Compartilh√°vel entre sess√µes

### 2. Embedding Cache
- Cachear embeddings de quest√µes
- Reduz lat√™ncia de RAG ainda mais

### 3. Batch Embeddings
- Processar m√∫ltiplos textos em uma chamada
- Suportado por OpenAI e Gemini

### 4. LLM Response Caching
- Cachear respostas do LLM por (question, answer, rubric)
- √ötil para demonstra√ß√µes repetidas

### 5. Observability Dashboard
- Grafana/Prometheus para m√©tricas em tempo real
- Tokens consumidos, lat√™ncias, cache hit rate

---

## üìù Changelog

### 2026-02-10 - Session 3: Bug Fixes (23:00-23:12)

#### Fix #3: Robust JSON Parsing Fallback (`6d47c56`)
**Problema:** `JSONDecodeError: Expecting value: line 1 column 1 (char 0)` no DSPy Arbiter

**Causa:**
- LLM retornando string vazia ou texto n√£o-JSON
- C√≥digo tentava `json.loads()` sem valida√ß√£o pr√©via

**Solu√ß√£o:**
- Valida√ß√£o antes do parsing: checa se string vazia ou n√£o come√ßa com `{`
- Fallback gracioso:
  - **Arbiter:** usa m√©dia das 2 corre√ß√µes anteriores (nota justa)
  - **Examiner:** retorna 0.0 com mensagem de erro
- Try-catch em JSON parsing com fallback
- Logs detalhados para debug

**Arquivos modificados:**
- `src/agents/dspy_arbiter.py`
- `src/agents/dspy_examiner.py`

---

#### Fix #2: Normalize Grades to 0-10 Scale (`fd4b42e`)
**Problema:** Notas aparecendo de 0-1 em vez de 0-10

**Causa:**
- LLM retornando notas normalizadas (0-1) em vez de absolutas (0-10)
- Prompts n√£o eram expl√≠citos sobre a escala

**Solu√ß√£o:**
- Prompts atualizados com instru√ß√µes expl√≠citas: "Use escala ABSOLUTA (0 at√© peso m√°ximo), N√ÉO normalizada (0-1)"
- Auto-detec√ß√£o no schema: se todas as notas ‚â§ 1.5, multiplica por 10
- Log de warning quando normaliza√ß√£o autom√°tica √© aplicada

**Exemplo de instru√ß√£o adicionada:**
> "Se o crit√©rio vale 4.0 pontos e o aluno acertou parcialmente (75%), atribua 3.0 pontos, N√ÉO 0.75."

**Arquivos modificados:**
- `src/config/prompts.py` (CORRECTOR_SYSTEM_PROMPT, ARBITER_SYSTEM_PROMPT)
- `src/domain/schemas.py` (AgentCorrection.calculate_total_if_missing)

---

### 2026-02-10 - Session 2: Performance Optimization (`1e3b2f0`)

#### Otimiza√ß√£o #1: Increased Parallelism (5x speedup)
**Mudan√ßas:**
- `API_CONCURRENCY` default: 2 ‚Üí 10
- Configur√°vel via env var `API_CONCURRENCY`

**Impacto:**
- 5x mais requisi√ß√µes simult√¢neas
- Tempo estimado: 10 alunos √ó 3 quest√µes de ~10min ‚Üí ~2-3min

---

#### Otimiza√ß√£o #2: Performance Logging
**Mudan√ßas:**
- Adicionado `measure_time` context manager em:
  - `src/agents/dspy_examiner.py` (tempo por corre√ß√£o)
  - `src/agents/dspy_arbiter.py` (tempo por arbitragem)
  - `src/rag/retriever.py` (j√° tinha)

**Logs gerados:**
```
‚è≥ Iniciando: DSPy Examiner CORRETOR_1 - Question Q1...
‚úÖ Conclu√≠do: DSPy Examiner CORRETOR_1 - Question Q1 em 3.2456 segundos.
```

---

#### Otimiza√ß√£o #3: Documentation
**Criado:**
- `PERFORMANCE.md` (este arquivo)
  - Benchmarks esperados
  - Configura√ß√£o de env vars
  - Troubleshooting de rate limits
  - Pr√≥ximas otimiza√ß√µes

---

### 2026-02-10 - Session 1: Bug Fixes Anteriores

#### Fixes realizados antes desta sess√£o:
- ‚úÖ Fixed asyncio Semaphore cross-event-loop error (per-loop semaphore)
- ‚úÖ Fixed LLM import-time creation (lazy init in workflow nodes)
- ‚úÖ Fixed DSPy examiner validation loop (schema normalization)
- ‚úÖ Fixed test: `test_connection()` sync (DSPy predict is sync)
- ‚úÖ Cleaned `requirements.txt` (removed pytest-asyncio)

---

## üéØ Resumo de Melhorias

### Performance
- **5x paraleliza√ß√£o** (API_CONCURRENCY 2 ‚Üí 10)
- **RAG Cache** (j√° implementado, verificado)
- **Streamlit Progress** (j√° implementado, verificado)
- **Performance logging** (adicionado em agents DSPy)

### Qualidade
- **Notas normalizadas 0-10** (auto-detec√ß√£o + prompts expl√≠citos)
- **JSON parsing robusto** (fallbacks graciosos, sem crashes)
- **Observabilidade** (logs detalhados, measure_time)

### Resultados Esperados
- **Velocidade:** 10 alunos √ó 3 quest√µes de ~10min ‚Üí ~2-3min
- **Confiabilidade:** Sem crashes em respostas inv√°lidas do LLM
- **Precis√£o:** Notas sempre na escala correta (0-10)

---

**Autor:** Alan Turing (AI Assistant)  
**Projeto:** ai-grading-system (TCC Lucas Savino)  
**Repo:** https://github.com/savinoo/ai-grading-system
